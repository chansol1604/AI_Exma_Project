# -*- coding: utf-8 -*-
"""exam03_keras_xor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SsDuuatQnQc2s9VSjXXIgc1a_E9aR4Sz

# 인공지능의 역사

https://itwiki.kr/w/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5
"""

import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import matplotlib.pyplot as plt

training_data = np.array(
    [[0, 0], [0, 1], [1, 0], [1, 1]])
target_data = np.array(
    [[0], [1], [1], [0]])

model = Sequential()            # 빈 모델 생성
model.add(Dense(32, input_dim = 2, activation = 'relu'))  # 32 = 만들 퍼셉트론의 수, input_dim = 입력개수
                                                          # 기울기 소실 문제를 해결하기 위해 'relu' 사용
                                                          # 'sigmoid'를 사용할 경우 미분값을 계속 곱할때 기울기 소실이 발생
model.add(Dense(1, activation = 'sigmoid'))               # 'sigmoid' 은 step function과 비슷 , 0과 1이 곡선으로 이어져 있어서 미분이 가능
                                                          # 차원 확장, xor의 경우 3차원으로 만들어 결과값이 1과 0인 값으로 잘라냄
                                                          # https://www.learndatasci.com/glossary/sigmoid-function/
model.compile(loss = 'mse', optimizer = 'adam')
print(model.summary())

fit_hist = model.fit(training_data, target_data, epochs = 1000, verbose =1)
# x : 모델의 입력 데이터를 나타내는 Numpy 배열 또는 배열의 리스트
# y : 모델의 입력 데이터를 나타내는 Numpy 배열 또는 배열의 리스트
# batch_size : 한 번에 처리되는 샘플의 수를 나타내는 정수 값. 기본값은 32
# epochs : 모델이 학습할 총 횟수를 나타내는 정수 값
# verbose : 학습 과정을 어떻게 출력할 것인지를 결정하는 값. 0, 1, 2 중 하나의 값
#        0일 경우 출력이 없고, 1일 경우 진행 막대(progress bar)가 표시되고, 2일 경우 에포크마다 한 줄씩 출력

plt.plot(fit_hist.history['loss'])
plt.show()

print(int(model.predict(np.array([[0, 0]]))[0][0].round()))
print(int(model.predict(np.array([[1, 0]]))[0][0].round()))
print(int(model.predict(np.array([[0, 1]]))[0][0].round()))
print(int(model.predict(np.array([[1, 1]]))[0][0].round()))

