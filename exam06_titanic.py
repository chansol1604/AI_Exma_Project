# -*- coding: utf-8 -*-
"""exam06_titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pGvKgY-DL0oDqT-kkIztnUaEwIAfHXJC
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn import preprocessing

pd.set_option('display.max_columns', 8)             # 화면에 출력된 칼럼수를 6개만 표시해라
#pd.set_option('display,unicode.east_asian', True)   # 한글을 출력할 때 줄과 글의 크기가 맞지 않을 때 맞춰줌

df = sns.load_dataset('titanic')
print(df.head(20))

df.info()

nan_deck = df['deck'].value_counts(dropna = False)
print(nan_deck)

print(df.head().isnull())

print(df.head().notnull())

print(df.isnull().sum())

df.dropna(axis = 'columns', thresh = 500, inplace =True)      # thresh 옵션 : NaN 값이 500개 이상이면 그 칼럼을 지워라
print(df.columns)

df_age = df.dropna(subset = ['age'], how = 'any', axis = 'rows' )    # 나이의 값이 있는 row만 남김,
# 칼럼이 2개일 때, how = all -> 둘다 NaN값일 때 제거, how = any -> 하나라도 NaN값이면 지워라
df_age.info()

mean_age = df['age'].mean()                   # pandas는 NaN 값을 빼고 평균을 계산
df['age'].fillna(mean_age, inplace = True)    # 나이는 이상치가 높지 않아서 평균값을 채워 넣어도 된다.
print(df.head(10))

most_freq = df['embark_town'].value_counts(dropna = True).idxmax()
print(most_freq)

df_most_freq = df['embark_town'].fillna(most_freq, inplace = False)
print(df_most_freq[825:830])
print(df[825:830])

df['embark_town'].fillna(method = 'ffill', inplace = True)      # method = 'ffill' -> 이전 값, method = 'bfill' -> 이후 값
# 엑셀 파일의 경우 파일의 데이터 병합이 일어났을 때 밑의 값은 NaN 값으로 채우기에 필요함
print(df[825:830])

df.info()

df.drop(['alive', 'embarked'], axis = 'columns', inplace = True)
df.info()

print(df.isnull().sum())

target = df[['survived']]
target

training_data = df.drop(['survived'], axis = 'columns')
training_data.columns

training_data.info()

value_data = training_data[['age', 'fare']]
print(value_data.columns)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_data = scaler.fit_transform(value_data)
value_data = pd.DataFrame(scaled_data, columns = value_data.columns)
print(value_data.head())

training_data.drop(['age','fare'], axis = 'columns', inplace = True)
print(training_data.head())

#onehot_data = pd.get_dummies(training_data)      # 가변수로 변환되지 않는 칼럼들도 존재함
onehot_data = pd.get_dummies(training_data, columns = training_data.columns, dtype=float)      # 강제로 모든 칼럼을 지정해서 바꿈
onehot_data.info()

training_data = pd.concat([value_data, onehot_data], axis = 'columns')
training_data.info()

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(training_data, target, test_size = 0.2)

print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(128, input_dim =34, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(256, activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(512, activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(256, activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(128, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(64, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(32, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(1, activation = 'sigmoid'))
model.summary()

model.compile(loss = 'mse', optimizer = 'adam',metrics = ['binary_accuracy'])
fit_hist = model.fit(X_train, Y_train, batch_size = 50, epochs = 30, validation_split = 0.2, verbose =1)

import matplotlib.pyplot as plt
plt.plot(fit_hist.history['binary_accuracy'])
plt.plot(fit_hist.history['val_binary_accuracy'])
plt.show()

score = model.evaluate(X_test, Y_test, verbose = 0)
print('loss :', score[0])
print('accuracy :', score[1])

