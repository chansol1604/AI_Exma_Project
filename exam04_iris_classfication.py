# -*- coding: utf-8 -*-
"""exam04_iris_classfication.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XuFM-XpRFc2_ad6lExHgwt2T5BPjwBp9
"""

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder         # 데이터를 변환하는 함수

iris = load_iris()
print(type(iris))
print('================= data shape =================')
print('Data', iris.data.shape)
print('Label', iris.target.shape)
print('First five data :\n', iris.data[0:5])
print('First Five label :', iris.target[0:5])
print('iris dataset keys\n', iris.keys())

iris.feature_names

iris.target_names

import pandas as pd

iris_dataframe = pd.DataFrame(iris.data, columns = iris.feature_names)

pd.plotting.scatter_matrix(iris_dataframe, c = iris.target,
                           figsize = (10,10), marker = 'o', hist_kwds = {'bins' : 10}, s=60, alpha = 0.7)
# 도표 사이즈. 좌표의 점을 o로 표현, 분포도 그릴때 막대를 20개로 나눠라, 동그라미의 사이즈, 투명도
plt.show()

x = iris.data
y = iris.target.reshape(-1,1)       # .reshape(-1,1) -> 객체 하나하나를 분리하기 위해서 사용
print(y[0::50])

encoder = OneHotEncoder(sparse_output = False)
encoded_y = encoder.fit_transform(y)                # 값을 [1, 0, 0] 형식처럼 바꾸기 위해 사용
print(encoded_y.shape)
print(encoded_y[::50])

X_train, X_test, Y_train, Y_test = train_test_split(
    x, encoded_y, test_size = 0.2)        # 연습용 데이터, 검증용 데이터 나누기, 20% 만큼 떼어놓음
print(X_train.shape, Y_train.shape)
print(X_test.shape, Y_test.shape)

model = Sequential()
model.add(Dense(256, input_dim = 4, activation = 'relu'))   # weight 4*256개, bias 256개, param = 1280
model.add(Dense(128, activation = 'relu'))                  # weight 256*128개, bias 128개. param = 32896
model.add(Dense(512, activation = 'relu'))                  # weight 128*512개, bias 512개. param = 66048
model.add(Dense(3, activation = 'softmax'))                 # weight 512*3개, bias 3개 , param = 1539
                                                            # softmax 나올 값들을 확률로 계산, 가장 높은 확률을 이용

model.summary()

opt = Adam(learning_rate = 0.001)       # 경사 하강 알고리즘, RMSProp과 Momentum 방식을 합친 알고리
model.compile(opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])

fit_hist = model.fit(X_train, Y_train, batch_size = 5, epochs = 50, verbose = 1)

score = model.evaluate(X_test, Y_test, verbose=0)     # 모델 값을 검증해주는 함수(loss 값, accuracy 값)
print('Final test set accuracy :',score[1])

score

plt.plot(fit_hist.history['accuracy'])
plt.show()

labels = iris.target_names
my_sample = np.random.randint(30)
sample = X_test[my_sample]
print(sample)
sample = sample.reshape(1,4)
print(sample)
pred = model.predict(sample)  # 3 값을 합치면 1에 가까운 값이 나옴
print('pred is', pred)  # 'setosa', 'versicolor', 'virginica' 중 맞을 확률이 각각 출력됨
print('actual is :', Y_test[my_sample])     # 실제 검증 값
print('Target :', labels[np.argmax(Y_test[my_sample])])     # 원소 중에 가장 큰 인덱스를 반환
print('Prediction after learning is :', labels[np.argmax(pred)])    # 예측한 값 중 가장 큰 값

